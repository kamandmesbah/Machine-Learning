{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQiUBcMai0BN",
        "outputId": "7c5b9393-f18e-45ff-8816-399884be5c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the entropy function\n",
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts)) * np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "    return entropy\n",
        "\n",
        "# Define the Information Gain function\n",
        "def InfoGain(data, split_attribute_name, target_name=\"label\"):\n",
        "    total_entropy = entropy(data[target_name])\n",
        "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts)) * entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain\n",
        "\n",
        "# Define the ID3 algorithm\n",
        "def ID3(data, originaldata, features, target_attribute_name=\"label\", parent_node_class = None):\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]\n",
        "    elif len(data) == 0:\n",
        "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name], return_counts=True)[1])]\n",
        "    elif len(features) == 0:\n",
        "        return parent_node_class\n",
        "    else:\n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
        "        item_values = [InfoGain(data, feature, target_attribute_name) for feature in features]\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "        tree = {best_feature:{}}\n",
        "        features = [i for i in features if i != best_feature]\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            subtree = ID3(sub_data, originaldata, features, target_attribute_name, parent_node_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "        return tree\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/mnt/data/adult.train.10k.discrete', header=None)\n",
        "test_data = pd.read_csv('/mnt/data/adult.test.10k.discrete', header=None)\n",
        "\n",
        "# Define column names\n",
        "columns = [\"label\", \"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
        "train_data.columns = columns\n",
        "test_data.columns = columns\n",
        "\n",
        "# Apply the ID3 algorithm\n",
        "features = train_data.columns.tolist()[1:]\n",
        "tree = ID3(train_data, train_data, features)\n",
        "\n",
        "def predict(tree, instance):\n",
        "    for nodes in tree.keys():\n",
        "        value = instance[nodes]\n",
        "        tree = tree[nodes][value]\n",
        "        prediction = 0\n",
        "\n",
        "        if type(tree) is dict:\n",
        "            prediction = predict(tree, instance)\n",
        "        else:\n",
        "            prediction = tree\n",
        "            break;\n",
        "\n",
        "    return prediction\n",
        "\n",
        " #accuracy\n",
        "def calculate_accuracy(df, tree):\n",
        "    df[\"predicted\"] = df.apply(predict, axis=1, args=(tree,))\n",
        "    accuracy = np.sum(df[\"label\"] == df[\"predicted\"]) / len(df)\n",
        "    return accuracy\n",
        "\n",
        "train_accuracy = calculate_accuracy(train_data, tree)\n",
        "test_accuracy = calculate_accuracy(test_data, tree)\n",
        "\n",
        "print(f'Train Accuracy: {train_accuracy}')\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVc-5rS4jIZO",
        "outputId": "8fff5b54-eccf-4f83-99ce-c1a04a8b9d80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8731\n",
            "Test Accuracy: 0.8731\n"
          ]
        }
      ]
    }
  ]
}